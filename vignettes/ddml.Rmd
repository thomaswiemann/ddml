---
title: "Get Started"
description: "A brief introduction to double/debiased machine learning using (short-)stacking in R."
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Work in progress. Check back soon!

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```


1. DDML estimation with a single learner
2. DDML estimation with multiple learners & stacking
3. Computational benefits of short-stacking


```{r}
# Load ddml
library(ddml)

# Construct variables from the included Angrist & Evans (1998) data
y = AE98[, "worked"]
D = AE98[, "morekids"]
Z = AE98[, "samesex"]
X = AE98[, c("age","agefst","black","hisp","othrace","educ")]
```

```{r}
learners_single <- list(what = mdl_xgboost,
                        args = list(nrounds = 100,
                                    max_depth = 1))
```


```{r}
# Estimate the local average treatment effect using short-stacking with base
#     learners ols, rlasso, and xgboost.
late_fit <- ddml_late(y, D, Z, X,
                      learners = learners_single,
                      sample_folds = 5,
                      silent = TRUE)
summary(late_fit)
```
```{r}
learners_multiple <- list(list(fun = ols),
                          list(fun = mdl_glmnet),
                          list(fun = mdl_xgboost,
                               args = list(nrounds = 100,
                                           max_depth = 1)))
```

```{r}
# Estimate the local average treatment effect using short-stacking with base
#     learners ols, rlasso, and xgboost.
late_fit <- ddml_late(y, D, Z, X,
                      learners = learners_multiple,
                      ensemble_type = 'nnls',
                      shortstack = TRUE,
                      sample_folds = 5,
                      silent = TRUE)
summary(late_fit)
```

```{r}
cat(" Stacking weights for E[Y|Z=0, X]: \n")
t(late_fit$weights$y_X_Z0)

cat("\n Stacking weights for E[Y|Z=1, X]: \n")
t(late_fit$weights$y_X_Z1)
```


```{r}
# Estimate the local average treatment effect using short-stacking with base
#     learners ols, rlasso, and xgboost.
late_fit <- ddml_late(y, D, Z, X,
                      learners = learners_multiple,
                      ensemble_type = c('singlebest', 'average'),
                      shortstack = TRUE,
                      sample_folds = 5,
                      silent = TRUE)
summary(late_fit)
```


```{r}
time_singlelearner <- system.time({late_fit <- ddml_late(y, D, Z, X,
                      learners = learners_single,
                      sample_folds = 5,
                      silent = TRUE)})

time_shortstacking <- system.time({late_fit <- ddml_late(y, D, Z, X,
                      learners = learners_multiple,
                      ensemble_type = 'nnls',
                      shortstack = TRUE,
                      sample_folds = 5,
                      silent = TRUE)})

time_stacking <- system.time({late_fit <- ddml_late(y, D, Z, X,
                      learners = learners_multiple,
                      ensemble_type = 'nnls',
                      shortstack = FALSE,
                      sample_folds = 5,
                      silent = TRUE)})


```

```{r}
cat("Time single learner:", time_singlelearner[1], "\n")
cat("Time short-stacking:", time_shortstacking[1], "\n")
cat("Time stacking:      ", time_stacking[1])

```


## References

Ahrens A, Hansen C B, Schaffer M E, Wiemann T (2023). "ddml: Double/debiased machine learning in Stata." <https://arxiv.org/abs/2301.09397>

Angrist J, Evans W, (1998). "Children and Their Parents' Labor Supply: Evidence 
    from Exogenous Variation in Family Size." American Economic
    Review, 88(3), 450-477.

Chernozhukov V, Chetverikov D, Demirer M, Duflo E, Hansen C B, Newey W, Robins J (2018). "Double/debiased machine learning for treatment and structural parameters." The Econometrics Journal, 21(1), C1-C68.

Wolpert D H (1992). "Stacked generalization." Neural Networks, 5(2), 241-259.


